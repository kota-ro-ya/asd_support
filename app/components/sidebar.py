"""
Sidebar component for parent AI question mode.
å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹é«˜ç²¾åº¦ãªå›ç­”ã‚’æä¾›
ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºã§å¾…ã¡æ™‚é–“ã‚’å¿«é©ã«
"""

import streamlit as st
import random
from pathlib import Path

from app.services.specialized_agent_service import SpecializedAgentService
from app.services.session_service import SessionService
from app.services.progress_service import ProgressService
from app.utils.file_handler import FileHandler
from app.utils.error_handler import ErrorHandler
from app.config.settings import Settings


def render_sidebar():
    """ä¿è­·è€…å‘ã‘AIè³ªå•ãƒ¢ãƒ¼ãƒ‰ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’æç”»ï¼ˆå°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼‰"""
    
    with st.sidebar:
        st.header("ğŸ‘¥ ä¿è­·è€…å‘ã‘AIç›¸è«‡")
        
        st.markdown(
            """
            <div style="padding: 0.8rem; background-color: #F3E5F5; border-radius: 0.5rem; margin-bottom: 1rem;">
                <p style="margin: 0; font-size: 0.85rem;">
                <strong>ğŸ“ å°‚é–€å®¶ãƒãƒ¼ãƒ ãŒå›ç­”</strong><br>
                ğŸ§  è‡¨åºŠå¿ƒç†å£« / âš•ï¸ å°å…ç§‘åŒ»<br>
                ğŸ« ç‰¹åˆ¥æ”¯æ´æ•™è‚² / ğŸ’™ å®¶æ—æ”¯æ´
                </p>
            </div>
            """,
            unsafe_allow_html=True
        )
        
        st.divider()
        
        # ã‚ˆãã‚ã‚‹è³ªå•ãƒ¢ãƒ¼ãƒ‰ï¼ˆå°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ï¼‰
        render_faq_mode()
        
        st.divider()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±è¡¨ç¤º
        nickname = SessionService.get_nickname()
        if nickname:
            st.caption(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {nickname}")


def render_faq_mode():
    """
    ã‚ˆãã‚ã‚‹è³ªå•ãƒ¢ãƒ¼ãƒ‰ã®UIã‚’æç”»ï¼ˆå°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ãƒ»ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰
    """
    # FAQè³ªå•ãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿
    faq_path = Settings.DATA_DIR / "parent_guide_data.json"
    faq_data = FileHandler.read_json(faq_path)
    
    if faq_data and "faq_questions" in faq_data:
        questions = faq_data["faq_questions"]
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¡¨ç¤ºè³ªå•ãƒªã‚¹ãƒˆãŒä¿å­˜ã•ã‚Œã¦ã„ãªã„å ´åˆã€åˆæœŸåŒ–
        if "displayed_faq_questions" not in st.session_state:
            # ãƒ©ãƒ³ãƒ€ãƒ ã«5ã¤ã®è³ªå•ã‚’é¸æŠ
            if len(questions) > 5:
                st.session_state.displayed_faq_questions = random.sample(questions, 5)
            else:
                st.session_state.displayed_faq_questions = questions
        
        displayed_questions = st.session_state.displayed_faq_questions
        
        st.subheader("ğŸ’¡ ã‚ˆãã‚ã‚‹è³ªå•")
        
        # è³ªå•ãƒªã‚¹ãƒˆã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã™ã‚‹ãƒœã‚¿ãƒ³
        col1, col2 = st.columns([3, 1])
        with col1:
            st.write("æ°—ã«ãªã‚‹è³ªå•ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š")
        with col2:
            if st.button("ğŸ”„", help="è³ªå•ãƒªã‚¹ãƒˆã‚’æ›´æ–°", key="refresh_faq_btn"):
                # æ–°ã—ã„è³ªå•ãƒªã‚¹ãƒˆã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
                if len(questions) > 5:
                    st.session_state.displayed_faq_questions = random.sample(questions, 5)
                else:
                    st.session_state.displayed_faq_questions = questions
                st.rerun()
        
        # è³ªå•ã®é¸æŠ
        selected_question = st.radio(
            "è³ªå•ãƒªã‚¹ãƒˆ",
            displayed_questions,
            key="faq_question_selector",
            label_visibility="collapsed"
        )
        
        # å›ç­”ãƒ¢ãƒ¼ãƒ‰ã®é¸æŠ
        response_mode = st.radio(
            "å›ç­”ãƒ¢ãƒ¼ãƒ‰",
            ["ğŸ’¬ 1äººã®å°‚é–€å®¶ã‚’é¸ã¶ï¼ˆæ—©ã„ãƒ»ãŠã™ã™ã‚ï¼‰", "ğŸ‘¥ 4äººã®å°‚é–€å®¶ï¼ˆé †ç•ªã«å›ç­”ï¼‰", "ğŸ”„ çµ±åˆå›ç­”ï¼ˆç·åˆçš„ï¼‰"],
            key="sidebar_response_mode",
            help="1äººã®å°‚é–€å®¶ï¼š3-5ç§’ã§å›ç­”é–‹å§‹ã€å°‚é–€å®¶ã‚’é¸ã¹ã¾ã™\n4äººã®å°‚é–€å®¶ï¼šã™ãã«é–‹å§‹ã€é †ç•ªã«è¡¨ç¤º\nçµ±åˆå›ç­”ï¼š15-20ç§’å¾Œã«çµ±åˆã—ãŸå›ç­”"
        )
        
        # 1äººã®å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€å°‚é–€å®¶ã‚’é¸æŠ
        selected_expert = None
        if "1äººã®å°‚é–€å®¶" in response_mode:
            st.markdown("**å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š**")
            selected_expert = st.radio(
                "å°‚é–€å®¶é¸æŠ",
                [
                    "ğŸ§  è‡¨åºŠå¿ƒç†å£«",
                    "âš•ï¸ å°å…ç§‘åŒ»",
                    "ğŸ« ç‰¹åˆ¥æ”¯æ´æ•™è‚²å°‚é–€å®¶",
                    "ğŸ’™ å®¶æ—æ”¯æ´å°‚é–€å®¶"
                ],
                key="sidebar_selected_expert",
                help="ğŸ§  è‡¨åºŠå¿ƒç†å£«ï¼šABAã€TEACCHã€SSTãªã©ã®å°‚é–€çŸ¥è­˜\nâš•ï¸ å°å…ç§‘åŒ»ï¼šåŒ»å­¦çš„è¦‹åœ°ã€ç™ºé”è©•ä¾¡\nğŸ« ç‰¹åˆ¥æ”¯æ´æ•™è‚²ï¼šå­¦æ ¡ã§ã®æ”¯æ´ã€åˆç†çš„é…æ…®\nğŸ’™ å®¶æ—æ”¯æ´ï¼šä¿è­·è€…ã®ãƒ¡ãƒ³ã‚¿ãƒ«ã‚±ã‚¢ã€ãã‚‡ã†ã ã„æ”¯æ´",
                label_visibility="collapsed"
            )
        
        # å£èª¿ã®é¸æŠ
        tone_mode = st.radio(
            "å£èª¿",
            ["ğŸ˜Š ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ï¼ˆãŠã™ã™ã‚ï¼‰", "ğŸ“– æ¨™æº–"],
            key="sidebar_tone_mode",
            help="ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ï¼šè¦ªã—ã¿ã‚„ã™ãæŸ”ã‚‰ã‹ã„è¡¨ç¾\næ¨™æº–ï¼šå°‚é–€çš„ã§å½¢å¼çš„ãªè¡¨ç¾"
        )
        
        # è³ªå•ãƒœã‚¿ãƒ³
        if st.button("ğŸ’¬ å°‚é–€å®¶ã«è³ªå•ã™ã‚‹", use_container_width=True, type="primary", key="ask_faq_btn"):
            if selected_question:
                tone = "friendly" if "ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼" in tone_mode else "standard"
                
                try:
                    specialized_service = SpecializedAgentService()
                    
                    st.markdown("---")
                    
                    if "1äººã®å°‚é–€å®¶" in response_mode:
                        # é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã«ã‚ˆã‚‹å›ç­”
                        if selected_expert:
                            agent_id = specialized_service.get_agent_id_from_display_name(selected_expert)
                            if agent_id:
                                agent_info = specialized_service.get_agent_info(agent_id)
                                st.markdown(f"**{agent_info['icon']} {agent_info['name']}ã‹ã‚‰ã®å›ç­”:**")
                                
                                stream_generator = specialized_service.generate_single_expert_response_stream(
                                    agent_id=agent_id,
                                    question=selected_question,
                                    context="",
                                    tone=tone
                                )
                                full_answer = st.write_stream(stream_generator)
                                
                                # ä¼šè©±å±¥æ­´ã«ä¿å­˜
                                save_conversation(selected_question, full_answer, f"{agent_info['name']}")
                            else:
                                st.error("å°‚é–€å®¶ã®é¸æŠã«å¤±æ•—ã—ã¾ã—ãŸ")
                        else:
                            st.warning("å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„")
                        
                    elif "4äººã®å°‚é–€å®¶" in response_mode:
                        # é †ç•ªãƒ¢ãƒ¼ãƒ‰ï¼š4äººãŒé †ç•ªã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
                        full_answer = display_sequential_responses(
                            specialized_service,
                            selected_question,
                            "",
                            tone
                        )
                        
                        # ä¼šè©±å±¥æ­´ã«ä¿å­˜
                        save_conversation(selected_question, full_answer, "å°‚é–€å®¶4äººï¼ˆé †ç•ªï¼‰")
                        
                    else:  # çµ±åˆå›ç­”
                        # çµ±åˆãƒ¢ãƒ¼ãƒ‰ï¼š15-20ç§’å¾…ã£ã¦ã‹ã‚‰çµ±åˆå›ç­”
                        stream_generator = specialized_service.generate_comprehensive_response_stream(
                            question=selected_question,
                            context="",
                            tone=tone
                        )
                        full_answer = st.write_stream(stream_generator)
                        
                        # ä¼šè©±å±¥æ­´ã«ä¿å­˜
                        save_conversation(selected_question, full_answer, "å°‚é–€å®¶ãƒãƒ¼ãƒ ï¼ˆçµ±åˆï¼‰")
                    
                except Exception as e:
                    ErrorHandler.handle_error(e, "å°‚é–€å®¶ãƒãƒ¼ãƒ ã®å›ç­”ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            else:
                st.warning("è³ªå•ã‚’é¸æŠã—ã¦ãã ã•ã„")
        
        st.divider()
        
        # ã‚«ã‚¹ã‚¿ãƒ è³ªå•
        st.subheader("âœï¸ è‡ªç”±ã«è³ªå•")
        custom_question = st.text_area(
            "è‡ªåˆ†ã§è³ªå•ã‚’å…¥åŠ›ã§ãã¾ã™",
            placeholder="ä¾‹: å­ã©ã‚‚ãŒæœèµ·ãã‚‰ã‚Œãªã„ã¨ãã¯ã©ã†ã™ã‚Œã°è‰¯ã„ã§ã™ã‹ï¼Ÿ",
            height=100,
            key="faq_custom_question"
        )
        
        if st.button("ğŸ“ ã“ã®è³ªå•ã‚’å°‚é–€å®¶ã«èã", use_container_width=True, key="ask_custom_faq_btn"):
            if custom_question.strip():
                tone = "friendly" if "ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼" in tone_mode else "standard"
                
                try:
                    specialized_service = SpecializedAgentService()
                    
                    st.markdown("---")
                    
                    if "1äººã®å°‚é–€å®¶" in response_mode:
                        # é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã«ã‚ˆã‚‹å›ç­”
                        if selected_expert:
                            agent_id = specialized_service.get_agent_id_from_display_name(selected_expert)
                            if agent_id:
                                agent_info = specialized_service.get_agent_info(agent_id)
                                st.markdown(f"**{agent_info['icon']} {agent_info['name']}ã‹ã‚‰ã®å›ç­”:**")
                                
                                stream_generator = specialized_service.generate_single_expert_response_stream(
                                    agent_id=agent_id,
                                    question=custom_question,
                                    context="",
                                    tone=tone
                                )
                                full_answer = st.write_stream(stream_generator)
                                
                                # ä¼šè©±å±¥æ­´ã«ä¿å­˜
                                save_conversation(custom_question, full_answer, f"{agent_info['name']}")
                            else:
                                st.error("å°‚é–€å®¶ã®é¸æŠã«å¤±æ•—ã—ã¾ã—ãŸ")
                        else:
                            st.warning("å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„")
                        
                    elif "4äººã®å°‚é–€å®¶" in response_mode:
                        # é †ç•ªãƒ¢ãƒ¼ãƒ‰ï¼š4äººãŒé †ç•ªã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
                        full_answer = display_sequential_responses(
                            specialized_service,
                            custom_question,
                            "",
                            tone
                        )
                        
                        # ä¼šè©±å±¥æ­´ã«ä¿å­˜
                        save_conversation(custom_question, full_answer, "å°‚é–€å®¶4äººï¼ˆé †ç•ªï¼‰")
                        
                    else:  # çµ±åˆå›ç­”
                        # çµ±åˆãƒ¢ãƒ¼ãƒ‰ï¼š15-20ç§’å¾…ã£ã¦ã‹ã‚‰çµ±åˆå›ç­”
                        stream_generator = specialized_service.generate_comprehensive_response_stream(
                            question=custom_question,
                            context="",
                            tone=tone
                        )
                        full_answer = st.write_stream(stream_generator)
                        
                        # ä¼šè©±å±¥æ­´ã«ä¿å­˜
                        save_conversation(custom_question, full_answer, "å°‚é–€å®¶ãƒãƒ¼ãƒ ï¼ˆçµ±åˆï¼‰")
                    
                except Exception as e:
                    ErrorHandler.handle_error(e, "å°‚é–€å®¶ãƒãƒ¼ãƒ ã®å›ç­”ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            else:
                st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    else:
        st.error("è³ªå•ãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")


def display_sequential_responses(service, question, context, tone):
    """å„å°‚é–€å®¶ãŒé †ç•ªã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º"""
    full_answer = ""
    current_agent = None
    current_response = ""
    placeholder = None
    
    for chunk_data in service.generate_sequential_expert_responses_stream(question, context, tone):
        if chunk_data["chunk"] == "__START__":
            # æ–°ã—ã„å°‚é–€å®¶ã®é–‹å§‹
            current_agent = chunk_data
            current_response = ""
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
            st.markdown(f"### {chunk_data['agent_icon']} {chunk_data['agent_name']}ã®è¦‹è§£")
            placeholder = st.empty()
            
        elif chunk_data["chunk"] == "__END__":
            # ç¾åœ¨ã®å°‚é–€å®¶ã®å›ç­”çµ‚äº†
            full_answer += f"\n\n### {current_agent['agent_icon']} {current_agent['agent_name']}ã®è¦‹è§£\n{current_response}\n"
            current_agent = None
            current_response = ""
            placeholder = None
            
        else:
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
            current_response += chunk_data["chunk"]
            if placeholder:
                placeholder.markdown(current_response)
    
    return full_answer


def save_conversation(question, answer, ai_mode):
    """ä¼šè©±å±¥æ­´ã‚’ä¿å­˜"""
    user = SessionService.get_user()
    if user:
        progress_service = ProgressService()
        progress_service.add_conversation(
            user=user,
            ai_mode=ai_mode,
            question=question,
            answer=answer,
            topic_tags=["ã‚ˆãã‚ã‚‹è³ªå•"]
        )
