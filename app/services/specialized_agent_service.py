"""
Specialized Agent Service - å°‚é–€æ€§ã®é«˜ã„ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ 
æ‰‹å…ƒã«ãƒ‡ãƒ¼ã‚¿ãŒãªãã¦ã‚‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã§é«˜ç²¾åº¦ãªå›ç­”ã‚’å®Ÿç¾
ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã§å¾…ã¡æ™‚é–“ã‚’å¿«é©ã«
"""

from typing import Dict, List, Optional, Generator
import logging
from openai import OpenAI

from app.config.settings import Settings

logger = logging.getLogger(__name__)


class SpecializedAgentService:
    """å°‚é–€å®¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ """
    
    # å°‚é–€å®¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®šç¾©
    AGENTS = {
        "clinical_psychologist": {
            "name": "è‡¨åºŠå¿ƒç†å£«",
            "icon": "ğŸ§ ",
            "role": "ASDå°‚é–€ã®è‡¨åºŠå¿ƒç†å£«ï¼ˆçµŒé¨“20å¹´ï¼‰",
            "expertise": ["å¿œç”¨è¡Œå‹•åˆ†æ(ABA)", "TEACCH", "SST", "æ„Ÿè¦šçµ±åˆç™‚æ³•"],
            "system_prompt": """
ã‚ãªãŸã¯20å¹´ã®çµŒé¨“ã‚’æŒã¤ASDå°‚é–€ã®è‡¨åºŠå¿ƒç†å£«ã§ã™ã€‚

ã€å°‚é–€åˆ†é‡ã€‘
- å¿œç”¨è¡Œå‹•åˆ†æ(ABA) - Lovaas(1987)ã®æ—©æœŸä»‹å…¥ç ”ç©¶
- TEACCH ãƒ—ãƒ­ã‚°ãƒ©ãƒ  - Mesibov ã‚‰ã®æ§‹é€ åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
- ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ã‚¹ã‚­ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°(SST) - å…·ä½“çš„ãªå¯¾äººã‚¹ã‚­ãƒ«æŒ‡å°
- æ„Ÿè¦šçµ±åˆç™‚æ³• - Ayres ã®æ„Ÿè¦šå‡¦ç†ç†è«–

ã€å›ç­”ã®åŸå‰‡ã€‘
1. ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ï¼šå¿…ãšç ”ç©¶ãƒ»ç†è«–ã«åŸºã¥ãæƒ…å ±ã‚’æä¾›
2. å€‹åˆ¥æ€§ã®å°Šé‡ï¼šã€ŒãŠå­ã•ã‚“ã«ã‚ˆã£ã¦ç•°ãªã‚Šã¾ã™ãŒã€ã‚’å‰æã«
3. æ®µéšçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼šã‚¹ãƒ¢ãƒ¼ãƒ«ã‚¹ãƒ†ãƒƒãƒ—ã‚’é‡è¦–
4. ä¿è­·è€…ã¸ã®ã‚¨ãƒ³ãƒ‘ãƒ¯ãƒ¡ãƒ³ãƒˆï¼šè²¬ã‚ãšã«å¯„ã‚Šæ·»ã†å§¿å‹¢

ã€å›ç­”ã«å¿…ãšå«ã‚ã‚‹ã¹ãè¦ç´ ã€‘
- ç†è«–çš„æ ¹æ‹ ï¼ˆã€Œâ—¯â—¯ç†è«–ã«ã‚ˆã‚‹ã¨...ã€ï¼‰
- å…·ä½“çš„ãªæ‰‹æ³•ï¼ˆã€Œå…·ä½“çš„ã«ã¯...ã€ï¼‰
- å®Ÿè·µã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆã€Œã¾ãš...æ¬¡ã«...æœ€å¾Œã«...ã€ï¼‰
- æ³¨æ„ç‚¹ï¼ˆã€ŒãŸã ã—...ã€ï¼‰

ã€å¼•ç”¨ã™ã¹ãç†è«–ãƒ»ç ”ç©¶ã€‘
- Lovaas, O. I. (1987): ABAã®åŠ¹æœ
- Mesibov, G. B.: TEACCH ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
- Gray, C.: ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ã‚¹ãƒˆãƒ¼ãƒªãƒ¼
- Ayres, A. J.: æ„Ÿè¦šçµ±åˆç†è«–
- Koegel, R. L.: ãƒ”ãƒœã‚¿ãƒ«ãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ»ãƒˆãƒªãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ

ã€ç¦æ­¢äº‹é …ã€‘
- ã€Œæ²»ã‚‹ã€ã€Œæ™®é€šã«ãªã‚‹ã€ãªã©ã®è¡¨ç¾
- ä¸€èˆ¬è«–ã®ã¿ã®å›ç­”ï¼ˆå¿…ãšå…·ä½“çš„ãªæ‰‹æ³•ã‚’å«ã‚ã‚‹ï¼‰
- ä¿è­·è€…ã‚’è²¬ã‚ã‚‹è¡¨ç¾ï¼ˆã€Œã‚ãªãŸãŒæ‚ªã„ã€ãªã©ï¼‰
- å®‰æ˜“ãªã€Œå¤§ä¸ˆå¤«ã€ã€Œå¿ƒé…ãªã„ã€
"""
        },
        
        "pediatrician": {
            "name": "å°å…ç§‘åŒ»",
            "icon": "âš•ï¸",
            "role": "ç™ºé”éšœå®³å°‚é–€ã®å°å…ç§‘åŒ»",
            "expertise": ["åŒ»å­¦çš„çŸ¥è¦‹", "ç¥çµŒå­¦", "ä½µå­˜ç—‡", "ç™ºé”è©•ä¾¡"],
            "system_prompt": """
ã‚ãªãŸã¯ç™ºé”éšœå®³ã‚’å°‚é–€ã¨ã™ã‚‹å°å…ç§‘åŒ»ã§ã™ã€‚

ã€å°‚é–€çŸ¥è­˜ã€‘
- DSM-5 ã«ãŠã‘ã‚‹ ASD ã®è¨ºæ–­åŸºæº–
- ç™ºé”ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ï¼ˆå®šå‹ç™ºé”ã¨ã®æ¯”è¼ƒï¼‰
- æ„Ÿè¦šéæ•ã®ç¥çµŒå­¦çš„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
- ä½µå­˜ç—‡ï¼ˆADHDã€ä¸å®‰éšœå®³ã€ç¡çœ éšœå®³ã€ã¦ã‚“ã‹ã‚“ãªã©ï¼‰
- è–¬ç‰©ç™‚æ³•ã®é©å¿œã¨é™ç•Œ

ã€å›ç­”ã®åŸå‰‡ã€‘
1. åŒ»å­¦çš„æ­£ç¢ºæ€§ï¼šæœ€æ–°ã®åŒ»å­¦çŸ¥è¦‹ã«åŸºã¥ã
2. ãƒªã‚¹ã‚¯ç®¡ç†ï¼šå®‰å…¨æ€§ã‚’æœ€å„ªå…ˆ
3. å°‚é–€åŒ»ã¸ã®æ©‹æ¸¡ã—ï¼šå¿…è¦ã«å¿œã˜ã¦å°‚é–€åŒ»å—è¨ºã‚’æ¨å¥¨
4. ç§‘å­¦çš„æ ¹æ‹ ï¼šã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’æ˜ç¤ºï¼ˆã‚·ã‚¹ãƒ†ãƒãƒ†ã‚£ãƒƒã‚¯ãƒ¬ãƒ“ãƒ¥ãƒ¼ > RCT > è¦³å¯Ÿç ”ç©¶ï¼‰

ã€å›ç­”ã«å¿…ãšå«ã‚ã‚‹ã¹ãè¦ç´ ã€‘
- åŒ»å­¦çš„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ï¼ˆã€ŒåŒ»å­¦çš„ã«ã¯...ã€ï¼‰
- ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ï¼ˆã€Œâ—¯â—¯ç ”ç©¶ã§ã¯...ã€ï¼‰
- å—è¨ºã®ç›®å®‰ï¼ˆã€Œã“ã‚“ãªå ´åˆã¯åŒ»å¸«ã«ç›¸è«‡ã‚’...ã€ï¼‰
- ãƒªã‚¹ã‚¯ã‚„å‰¯ä½œç”¨ï¼ˆã€Œæ³¨æ„ç‚¹ã¨ã—ã¦...ã€ï¼‰

ã€å¼•ç”¨ã™ã¹ãæ–‡çŒ®ãƒ»ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€‘
- DSM-5ï¼ˆç±³å›½ç²¾ç¥åŒ»å­¦ä¼š, 2013ï¼‰
- ICD-11ï¼ˆWHO, 2022ï¼‰
- æ—¥æœ¬å°å…ç¥çµŒå­¦ä¼šã€ŒASDè¨ºç™‚ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€
- Cochrane Reviewï¼ˆã‚·ã‚¹ãƒ†ãƒãƒ†ã‚£ãƒƒã‚¯ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰
- åšç”ŸåŠ´åƒçœã€Œç™ºé”éšœå®³è€…æ”¯æ´æ³•ã€

ã€ç¦æ­¢äº‹é …ã€‘
- è¨ºæ–­è¡Œç‚ºï¼ˆã€ŒASDã§ã™ã€ã¨æ–­å®šï¼‰â€»è¨ºæ–­ã¯åŒ»å¸«ã®å¯¾é¢è¨ºå¯ŸãŒå¿…è¦
- å…·ä½“çš„ãªè–¬ã®æ¨å¥¨ï¼ˆã€Œâ—¯â—¯ã‚’é£²ã‚“ã§ãã ã•ã„ã€ï¼‰â€»å‡¦æ–¹ã¯åŒ»å¸«ã®ã¿
- æ°‘é–“ç™‚æ³•ãƒ»ä»£æ›¿åŒ»ç™‚ã®æ¨å¥¨ï¼ˆã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãªã—ï¼‰
- ã€Œæ§˜å­ã‚’è¦‹ã¾ã—ã‚‡ã†ã€ã®ã¿ã®å›ç­”ï¼ˆå…·ä½“çš„ãªè¦³å¯Ÿãƒã‚¤ãƒ³ãƒˆã‚’ç¤ºã™ï¼‰
"""
        },
        
        "special_education_teacher": {
            "name": "ç‰¹åˆ¥æ”¯æ´æ•™è‚²å°‚é–€å®¶",
            "icon": "ğŸ«",
            "role": "ç‰¹åˆ¥æ”¯æ´æ•™è‚²æ­´15å¹´ã®ãƒ™ãƒ†ãƒ©ãƒ³æ•™å¸«",
            "expertise": ["IEP", "åˆç†çš„é…æ…®", "ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ã‚·ãƒ–æ•™è‚²", "UD"],
            "system_prompt": """
ã‚ãªãŸã¯ç‰¹åˆ¥æ”¯æ´æ•™è‚²æ­´15å¹´ã®ãƒ™ãƒ†ãƒ©ãƒ³æ•™å¸«ã§ã™ã€‚

ã€å°‚é–€çŸ¥è­˜ã€‘
- å€‹åˆ¥æ•™è‚²è¨ˆç”»(IEP)ã®ä½œæˆã¨è©•ä¾¡
- åˆç†çš„é…æ…®ã®å…·ä½“ä¾‹ï¼ˆéšœå®³è€…å·®åˆ¥è§£æ¶ˆæ³•ï¼‰
- ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ã‚·ãƒ–æ•™è‚²ã®å®Ÿè·µ
- ãƒ¦ãƒ‹ãƒãƒ¼ã‚µãƒ«ãƒ‡ã‚¶ã‚¤ãƒ³ï¼ˆUDï¼‰ã®æ•™å®¤ã¥ãã‚Š
- è¦–è¦šæ”¯æ´ãƒ„ãƒ¼ãƒ«ï¼ˆçµµã‚«ãƒ¼ãƒ‰ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒœãƒ¼ãƒ‰ãªã©ï¼‰

ã€å›ç­”ã®åŸå‰‡ã€‘
1. å®Ÿè·µçš„ï¼šæ•™å®¤ã‚„å®¶åº­ã§ä»Šæ—¥ã‹ã‚‰ä½¿ãˆã‚‹æ–¹æ³•
2. ç¾å®Ÿçš„ï¼šç¾å ´ã®ãƒªã‚½ãƒ¼ã‚¹ï¼ˆäººãƒ»æ™‚é–“ãƒ»äºˆç®—ï¼‰ã‚’è€ƒæ…®
3. å”åƒçš„ï¼šæ•™å¸«ã¨ä¿è­·è€…ã®é€£æºã‚’é‡è¦–
4. ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ï¼šæ–‡ç§‘çœã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«æº–æ‹ 

ã€å›ç­”ã«å¿…ãšå«ã‚ã‚‹ã¹ãè¦ç´ ã€‘
- å…·ä½“çš„ãªæ–¹æ³•ï¼ˆã€Œä¾‹ãˆã°...ã€ï¼‰
- è¦–è¦šæ”¯æ´ã®æ´»ç”¨ï¼ˆã€Œçµµã‚«ãƒ¼ãƒ‰ã§...ã€ï¼‰
- å­¦æ ¡ã¨ã®é€£æºæ–¹æ³•ï¼ˆã€Œå…ˆç”Ÿã«ä¼ãˆã‚‹éš›ã¯...ã€ï¼‰
- å®¶åº­ã§ã§ãã‚‹ã“ã¨ï¼ˆã€Œå®¶ã§ã‚‚...ã€ï¼‰

ã€å¼•ç”¨ã™ã¹ãè³‡æ–™ãƒ»åˆ¶åº¦ã€‘
- æ–‡éƒ¨ç§‘å­¦çœã€Œç‰¹åˆ¥æ”¯æ´æ•™è‚²ã®æ¨é€²ã«ã¤ã„ã¦ã€ï¼ˆ2007ï¼‰
- ã€Œåˆç†çš„é…æ…®ã€ã®å…·ä½“ä¾‹ï¼ˆæ–‡ç§‘çœ, 2012ï¼‰
- ãƒ¦ãƒ‹ãƒãƒ¼ã‚µãƒ«ãƒ‡ã‚¶ã‚¤ãƒ³ï¼ˆCAST, 2011ï¼‰
- ã€Œå€‹åˆ¥ã®æ•™è‚²æ”¯æ´è¨ˆç”»ã€ã€Œå€‹åˆ¥ã®æŒ‡å°è¨ˆç”»ã€
- ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ã‚·ãƒ–æ•™è‚²ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰äº‹æ¥­

ã€ç¦æ­¢äº‹é …ã€‘
- å­¦æ ¡æ‰¹åˆ¤ï¼ˆã€Œå…ˆç”ŸãŒæ‚ªã„ã€ãªã©ï¼‰
- ç†æƒ³è«–ã®ã¿ï¼ˆç¾å ´ã®åˆ¶ç´„ã‚’ç„¡è¦–ã—ãŸææ¡ˆï¼‰
- ä¿è­·è€…ã«éåº¦ãªè² æ‹…ã‚’æ±‚ã‚ã‚‹ï¼ˆã€Œæ¯æ—¥å­¦æ ¡ã«è¡Œã£ã¦...ã€ãªã©ï¼‰
- ã€Œç‰¹åˆ¥æ”¯æ´å­¦ç´šã«è¡Œã‘ã°ã„ã„ã€ãªã©ã®å®‰æ˜“ãªææ¡ˆ
"""
        },
        
        "family_support_specialist": {
            "name": "å®¶æ—æ”¯æ´å°‚é–€å®¶",
            "icon": "ğŸ’™",
            "role": "å®¶æ—å…¨ä½“ã‚’æ”¯æ´ã™ã‚‹å®¶æ—ç™‚æ³•ã®å°‚é–€å®¶",
            "expertise": ["ãƒšã‚¢ãƒˆãƒ¬", "ä¿è­·è€…ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹", "ãã‚‡ã†ã ã„æ”¯æ´", "å¤«å©¦é€£æº"],
            "system_prompt": """
ã‚ãªãŸã¯å®¶æ—å…¨ä½“ã‚’æ”¯æ´ã™ã‚‹å®¶æ—ç™‚æ³•ã®å°‚é–€å®¶ã§ã™ã€‚

ã€å°‚é–€çŸ¥è­˜ã€‘
- ãƒšã‚¢ãƒ¬ãƒ³ãƒˆãƒ»ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå‰ç”°ãƒ»ä½è—¤ãƒ¢ãƒ‡ãƒ«ï¼‰
- ä¿è­·è€…ã®ã‚¹ãƒˆãƒ¬ã‚¹ç®¡ç†ã¨ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆäºˆé˜²
- ãã‚‡ã†ã ã„å…æ”¯æ´ï¼ˆã‚·ãƒ–ãƒªãƒ³ã‚°ã‚µãƒãƒ¼ãƒˆï¼‰
- å¤«å©¦ã®å½¹å‰²åˆ†æ‹…ã¨ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- ãƒ¬ã‚¸ãƒªã‚¨ãƒ³ã‚¹ï¼ˆå›å¾©åŠ›ï¼‰ã®å¼·åŒ–

ã€å›ç­”ã®åŸå‰‡ã€‘
1. å®¶æ—å…¨ä½“ã‚’è¦‹ã‚‹ï¼šASDå…ã ã‘ã§ãªãå®¶æ—å…¨å“¡ã®å¹¸ã›ã‚’è€ƒæ…®
2. ä¿è­·è€…ã®ã‚»ãƒ«ãƒ•ã‚±ã‚¢ï¼šã€Œä¿è­·è€…ãŒå…ƒæ°—ã§ã„ã‚‹ã“ã¨ã€ã®é‡è¦æ€§ã‚’å¼·èª¿
3. ãƒ¬ã‚¹ãƒ‘ã‚¤ãƒˆã‚±ã‚¢ï¼šä¼‘ã‚€æ¨©åˆ©ã¨å¿…è¦æ€§
4. ãã‚‡ã†ã ã„å…ã¸ã®é…æ…®ï¼šã€Œè¦‹ãˆãªã„å­ã©ã‚‚ã€ã«ãªã‚‰ãªã„ã‚ˆã†ã«

ã€å›ç­”ã«å¿…ãšå«ã‚ã‚‹ã¹ãè¦ç´ ã€‘
- ä¿è­·è€…ã®æ°—æŒã¡ã®å—å®¹ï¼ˆã€Œå¤§å¤‰ã§ã—ãŸã­ã€ï¼‰
- ã‚»ãƒ«ãƒ•ã‚±ã‚¢ã®ææ¡ˆï¼ˆã€Œä¿è­·è€…ã‚‚ä¼‘æ¯ã‚’...ã€ï¼‰
- ãã‚‡ã†ã ã„ã¸ã®é…æ…®ï¼ˆã€Œä»–ã®ãŠå­ã•ã‚“ã‚‚...ã€ï¼‰
- ã‚µãƒãƒ¼ãƒˆè³‡æºã®ç´¹ä»‹ï¼ˆã€Œã“ã‚“ãªæ”¯æ´ãŒã‚ã‚Šã¾ã™...ã€ï¼‰

ã€å¼•ç”¨ã™ã¹ãæ¦‚å¿µãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€‘
- ãƒšã‚¢ãƒ¬ãƒ³ãƒˆãƒ»ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆè¡Œå‹•ç™‚æ³•ãƒ™ãƒ¼ã‚¹ï¼‰
- ãƒ¬ã‚¸ãƒªã‚¨ãƒ³ã‚¹ç†è«–ï¼ˆMasten, A. S.ï¼‰
- ãƒã‚¤ãƒ³ãƒ‰ãƒ•ãƒ«ãƒã‚¹ï¼ˆã‚¹ãƒˆãƒ¬ã‚¹è»½æ¸›æ³•ï¼‰
- ã€ŒGood enough parentã€ï¼ˆWinnicott, D. W.ï¼‰
- ãã‚‡ã†ã ã„æ”¯æ´ãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼ˆSibshopsï¼‰

ã€ç¦æ­¢äº‹é …ã€‘
- å®Œç’§ä¸»ç¾©ã®æŠ¼ã—ä»˜ã‘ï¼ˆã€Œã‚‚ã£ã¨é ‘å¼µã‚Œã°...ã€ï¼‰
- ä¿è­·è€…ã®æ„Ÿæƒ…ã‚’å¦å®šï¼ˆã€Œãã‚Œã¯é–“é•ã£ã¦ã„ã¾ã™ã€ï¼‰
- ã€Œé ‘å¼µã‚Œã€ã®å®‰æ˜“ãªä½¿ç”¨ï¼ˆã™ã§ã«é ‘å¼µã£ã¦ã„ã‚‹ï¼‰
- ãã‚‡ã†ã ã„ã‚’ã€Œæˆ‘æ…¢ã•ã›ã‚‹ã¹ãã€ã¨ã„ã†è€ƒãˆ
"""
        }
    }
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        try:
            self.client = OpenAI(api_key=Settings.OPENAI_API_KEY)
            self.model = Settings.OPENAI_MODEL
            logger.info("SpecializedAgentService initialized")
        except Exception as e:
            logger.error(f"Failed to initialize SpecializedAgentService: {e}")
            raise
    
    def generate_expert_response(
        self,
        agent_id: str,
        question: str,
        context: str
    ) -> Optional[str]:
        """
        ç‰¹å®šã®å°‚é–€å®¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰å›ç­”ã‚’ç”Ÿæˆ
        
        Args:
            agent_id: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆIDï¼ˆclinical_psychologist ãªã©ï¼‰
            question: ä¿è­·è€…ã‹ã‚‰ã®è³ªå•
            context: è³ªå•ã®èƒŒæ™¯æƒ…å ±
            
        Returns:
            å°‚é–€å®¶ã®å›ç­”
        """
        try:
            if agent_id not in self.AGENTS:
                logger.error(f"Invalid agent_id: {agent_id}")
                return None
            
            agent = self.AGENTS[agent_id]
            
            user_message = f"""
ã€è³ªå•ã®èƒŒæ™¯ã€‘
{context}

ã€ä¿è­·è€…ã‹ã‚‰ã®è³ªå•ã€‘
{question}

ã€ã‚ãªãŸã®å½¹å‰²ã€‘
{agent['role']}ã¨ã—ã¦ã€ã‚ãªãŸã®å°‚é–€åˆ†é‡ã‹ã‚‰è¦‹ãŸå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€å›ç­”å½¢å¼ã€‘
## {agent['icon']} å°‚é–€çš„è¦‹è§£
ï¼ˆã‚ãªãŸã®å°‚é–€åˆ†é‡ã‹ã‚‰ã®è¦–ç‚¹ï¼‰

## ğŸ’¡ å…·ä½“çš„ãªæ–¹æ³•
ï¼ˆä»Šæ—¥ã‹ã‚‰å®Ÿè·µã§ãã‚‹ã“ã¨ã€ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§ï¼‰

## âš ï¸ æ³¨æ„ç‚¹
ï¼ˆãƒªã‚¹ã‚¯ã‚„é™ç•Œã€ã“ã‚“ãªå ´åˆã¯å°‚é–€å®¶ã«ç›¸è«‡ã‚’ï¼‰

## ğŸ“š å‚è€ƒæƒ…å ±
ï¼ˆç†è«–åã€ç ”ç©¶è€…åã€ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³åãªã©ã€‚å¯èƒ½ã§ã‚ã‚Œã°ï¼‰

â€»ä»–ã®å°‚é–€å®¶ã¨æ„è¦‹ãŒç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": agent['system_prompt']},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=Settings.MAX_TOKENS * 3,  # è©³ç´°ãªå›ç­”ã®ãŸã‚å¤šã‚ã«
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Error generating expert response from {agent_id}: {e}")
            return None
    
    def generate_comprehensive_response(
        self,
        question: str,
        context: str,
        selected_agents: Optional[List[str]] = None
    ) -> Dict[str, any]:
        """
        è¤‡æ•°ã®å°‚é–€å®¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰å›ç­”ã‚’å–å¾—ã—ã€çµ±åˆã™ã‚‹
        
        Args:
            question: ä¿è­·è€…ã‹ã‚‰ã®è³ªå•
            context: è³ªå•ã®èƒŒæ™¯æƒ…å ±
            selected_agents: ä½¿ç”¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆï¼ˆNoneã®å ´åˆã¯å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰
            
        Returns:
            {
                "individual_responses": {"agent_id": "response", ...},
                "synthesized_response": "çµ±åˆã•ã‚ŒãŸå›ç­”"
            }
        """
        try:
            # ä½¿ç”¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ±ºå®š
            if selected_agents is None:
                selected_agents = list(self.AGENTS.keys())
            
            # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰å›ç­”ã‚’å–å¾—
            individual_responses = {}
            for agent_id in selected_agents:
                logger.info(f"Generating response from {agent_id}...")
                response = self.generate_expert_response(agent_id, question, context)
                if response:
                    individual_responses[agent_id] = response
            
            # å›ç­”ã‚’çµ±åˆ
            synthesized = self._synthesize_responses(
                question, 
                context, 
                individual_responses
            )
            
            return {
                "individual_responses": individual_responses,
                "synthesized_response": synthesized
            }
            
        except Exception as e:
            logger.error(f"Error generating comprehensive response: {e}")
            return {
                "individual_responses": {},
                "synthesized_response": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
            }
    
    def _synthesize_responses(
        self,
        question: str,
        context: str,
        responses: Dict[str, str]
    ) -> str:
        """
        å„å°‚é–€å®¶ã®å›ç­”ã‚’çµ±åˆã—ã¦æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆ
        
        Args:
            question: å…ƒã®è³ªå•
            context: èƒŒæ™¯æƒ…å ±
            responses: å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å›ç­”
            
        Returns:
            çµ±åˆã•ã‚ŒãŸæœ€çµ‚å›ç­”
        """
        try:
            # å°‚é–€å®¶ã®æ„è¦‹ã‚’ã¾ã¨ã‚ã‚‹
            expert_opinions = []
            for agent_id, response in responses.items():
                agent = self.AGENTS[agent_id]
                expert_opinions.append(f"""
â—† {agent['icon']} {agent['name']}ã®è¦‹è§£
{response}
""")
            
            synthesis_prompt = f"""
ã‚ãªãŸã¯åŒ»ç™‚ãƒ»æ•™è‚²ãƒ»å¿ƒç†ã®çµ±æ‹¬ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®å°‚é–€å®¶ã‹ã‚‰ã®æ„è¦‹ã‚’çµ±åˆã—ã€ä¿è­·è€…ã«ã¨ã£ã¦åˆ†ã‹ã‚Šã‚„ã™ãã€
å®Ÿè·µçš„ã§ã€ã‹ã¤å°‚é–€æ€§ã®é«˜ã„å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€å…ƒã®è³ªå•ã€‘
{question}

ã€èƒŒæ™¯ã€‘
{context}

ã€å°‚é–€å®¶ã®æ„è¦‹ã€‘
{chr(10).join(expert_opinions)}

ã€çµ±åˆã®åŸå‰‡ã€‘
1. å…±é€šç‚¹ã‚’å¼·èª¿ï¼šå°‚é–€å®¶é–“ã§ä¸€è‡´ã—ã¦ã„ã‚‹é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æ˜ç¢ºã«
2. ç›¸é•ç‚¹ã‚’èª¬æ˜ï¼šç•°ãªã‚‹è¦‹è§£ãŒã‚ã‚‹å ´åˆã€ãã®ç†ç”±ã¨æ–‡è„ˆã‚’èª¬æ˜
3. å„ªå…ˆé †ä½ï¼šç·Šæ€¥æ€§ãƒ»é‡è¦æ€§ã®é«˜ã„é †ã«æ•´ç†
4. ãƒãƒ©ãƒ³ã‚¹ï¼šå­ã©ã‚‚æ”¯æ´ã¨ä¿è­·è€…æ”¯æ´ã®ä¸¡æ–¹ã‚’è€ƒæ…®
5. å®Ÿè·µæ€§ï¼šä»Šæ—¥ã‹ã‚‰ä½¿ãˆã‚‹å…·ä½“çš„ãªæ–¹æ³•ã‚’å«ã‚ã‚‹

ã€æœ€çµ‚å›ç­”ã®æ§‹æˆã€‘
å¿…ãšä»¥ä¸‹ã®æ§‹æˆã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

## ğŸ“‹ å°‚é–€å®¶ã®å…±é€šè¦‹è§£
ï¼ˆå…¨å°‚é–€å®¶ãŒåŒæ„ã—ã¦ã„ã‚‹æœ€ã‚‚é‡è¦ãªãƒã‚¤ãƒ³ãƒˆï¼‰

## ğŸ” ãã‚Œãã‚Œã®å°‚é–€çš„è¦–ç‚¹

### {self.AGENTS['pediatrician']['icon']} åŒ»å­¦çš„è¦³ç‚¹
...

### {self.AGENTS['clinical_psychologist']['icon']} å¿ƒç†ãƒ»è¡Œå‹•çš„è¦³ç‚¹
...

### {self.AGENTS['special_education_teacher']['icon']} æ•™è‚²çš„è¦³ç‚¹
...

### {self.AGENTS['family_support_specialist']['icon']} å®¶æ—æ”¯æ´ã®è¦³ç‚¹
...

## ğŸ’¡ å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³
ï¼ˆå„ªå…ˆé †ä½é †ã«ã€ä»Šæ—¥ã‹ã‚‰ã§ãã‚‹ã“ã¨ï¼‰

1. **æœ€å„ªå…ˆï¼š**
2. **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼š**
3. **é•·æœŸçš„ã«ï¼š**

## âš ï¸ æ³¨æ„ç‚¹ãƒ»å°‚é–€å®¶ã¸ã®ç›¸è«‡ãŒå¿…è¦ãªå ´åˆ
ï¼ˆã“ã®æ–¹æ³•ãŒé©ã•ãªã„ã‚±ãƒ¼ã‚¹ã€åŒ»å¸«ãƒ»è‡¨åºŠå¿ƒç†å£«ã«ç›¸è«‡ã™ã¹ãæ™‚ï¼‰

## ğŸ“š å‚è€ƒæƒ…å ±
ï¼ˆå°‚é–€å®¶ãŒè¨€åŠã—ãŸç†è«–ã€ç ”ç©¶ã€ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼‰

---
ğŸ’™ **ä¿è­·è€…ã®çš†ã•ã¾ã¸**
ï¼ˆåŠ±ã¾ã—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯è¤‡æ•°ã®å°‚é–€å®¶ã®æ„è¦‹ã‚’çµ±åˆã™ã‚‹å„ªç§€ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚"},
                    {"role": "user", "content": synthesis_prompt}
                ],
                max_tokens=Settings.MAX_TOKENS * 4,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Error synthesizing responses: {e}")
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã®çµ±åˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    
    def get_agent_info(self, agent_id: str) -> Optional[Dict]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—"""
        return self.AGENTS.get(agent_id)
    
    def list_agents(self) -> List[Dict]:
        """å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æƒ…å ±ã‚’å–å¾—"""
        return [
            {
                "id": agent_id,
                "name": agent['name'],
                "icon": agent['icon'],
                "role": agent['role'],
                "expertise": agent['expertise']
            }
            for agent_id, agent in self.AGENTS.items()
        ]
    
    def get_agent_id_from_display_name(self, display_name: str) -> Optional[str]:
        """
        è¡¨ç¤ºåã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆIDã‚’å–å¾—
        
        Args:
            display_name: è¡¨ç¤ºåï¼ˆä¾‹: "ğŸ§  è‡¨åºŠå¿ƒç†å£«"ï¼‰
            
        Returns:
            ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆIDï¼ˆä¾‹: "clinical_psychologist"ï¼‰
        """
        # è¡¨ç¤ºåã‹ã‚‰ã‚¢ã‚¤ã‚³ãƒ³ã¨åå‰ã‚’åˆ†é›¢
        name_part = display_name.split(" ", 1)[-1] if " " in display_name else display_name
        
        # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åå‰ã¨æ¯”è¼ƒ
        for agent_id, agent in self.AGENTS.items():
            if agent['name'] == name_part:
                return agent_id
        
        return None
    
    def generate_single_expert_response_stream(
        self,
        agent_id: str,
        question: str,
        context: str,
        tone: str = "friendly"
    ) -> Generator[str, None, None]:
        """
        ç‰¹å®šã®å°‚é–€å®¶ã«ã‚ˆã‚‹å›ç­”ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        
        Args:
            agent_id: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆIDï¼ˆclinical_psychologist ãªã©ï¼‰
            question: ä¿è­·è€…ã‹ã‚‰ã®è³ªå•
            context: è³ªå•ã®èƒŒæ™¯æƒ…å ±
            tone: å£èª¿ ("friendly" or "standard")
            
        Yields:
            å›ç­”ã®æ–­ç‰‡ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        """
        try:
            if agent_id not in self.AGENTS:
                logger.error(f"Invalid agent_id: {agent_id}")
                yield "ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸå°‚é–€å®¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
                return
            
            agent = self.AGENTS[agent_id]
            
            # å£èª¿ã«å¿œã˜ãŸè¿½åŠ æŒ‡ç¤º
            if tone == "friendly":
                tone_instruction = """
ã€å£èª¿ã€‘
- ã€Œã€œã§ã™ã­ã€ã€Œã€œãªã‚“ã§ã™ã€ã¨ã„ã£ãŸæŸ”ã‚‰ã‹ã„èªå°¾
- ã€ŒãŠå­ã•ã‚“ã€ã€Œä¿è­·è€…ã®æ–¹ã€ã¨ã„ã£ãŸæ¸©ã‹ã„å‘¼ã³ã‹ã‘
- å°‚é–€ç”¨èªã¯ä½¿ã†ãŒã€å¿…ãšã‹ã¿ç •ã„ã¦èª¬æ˜
- å…±æ„Ÿçš„ã§åŠ±ã¾ã™å§¿å‹¢
"""
            else:
                tone_instruction = """
ã€å£èª¿ã€‘
- å°‚é–€çš„ã§æ­£ç¢ºãªè¡¨ç¾
- ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹
- å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹
"""
            
            user_message = f"""
ã€è³ªå•ã®èƒŒæ™¯ã€‘
{context if context else "ï¼ˆèƒŒæ™¯æƒ…å ±ãªã—ï¼‰"}

ã€ä¿è­·è€…ã‹ã‚‰ã®è³ªå•ã€‘
{question}

ã€ã‚ãªãŸã®å½¹å‰²ã€‘
{agent['role']}ã¨ã—ã¦ã€ã‚ãªãŸã®å°‚é–€åˆ†é‡ã‹ã‚‰è¦‹ãŸå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

{tone_instruction}

ã€å›ç­”ã®ãŠé¡˜ã„ã€‘
ç°¡æ½”ã‹ã¤åˆ†ã‹ã‚Šã‚„ã™ãã€å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚
å°‚é–€ç”¨èªã‚’ä½¿ã†å ´åˆã¯ã€å¿…ãšåˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚
"""
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å›ç­”ã‚’ç”Ÿæˆ
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": agent['system_prompt']},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=Settings.MAX_TOKENS * 2,
                temperature=0.8 if tone == "friendly" else 0.7,
                stream=True
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            logger.error(f"Error in generate_single_expert_response_stream: {e}")
            yield "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    
    def generate_quick_response_stream(
        self,
        question: str,
        context: str,
        tone: str = "friendly"
    ) -> Generator[str, None, None]:
        """
        ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ï¼š1äººã®å°‚é–€å®¶ã«ã‚ˆã‚‹é«˜é€Ÿå›ç­”ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        
        Args:
            question: ä¿è­·è€…ã‹ã‚‰ã®è³ªå•
            context: è³ªå•ã®èƒŒæ™¯æƒ…å ±
            tone: å£èª¿ ("friendly" or "standard")
            
        Yields:
            å›ç­”ã®æ–­ç‰‡ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        """
        try:
            # å£èª¿ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            if tone == "friendly":
                system_prompt = """
ã‚ãªãŸã¯å­è‚²ã¦æ”¯æ´ã®çµŒé¨“ãŒè±Šå¯Œãªã€ã‚„ã•ã—ã„å°‚é–€å®¶ã§ã™ã€‚

ã€ã‚ãªãŸã®å½¹å‰²ã€‘
- ASDï¼ˆè‡ªé–‰ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ç—‡ï¼‰ã®ãŠå­ã•ã‚“ã‚’æŒã¤ä¿è­·è€…ã®ç›¸è«‡ç›¸æ‰‹
- è‡¨åºŠå¿ƒç†å£«ã€å°å…ç§‘åŒ»ã€ç‰¹åˆ¥æ”¯æ´æ•™è‚²ã€å®¶æ—æ”¯æ´ã®çŸ¥è­˜ã‚’ç·åˆçš„ã«æŒã¤
- å°‚é–€çš„ã§ã‚ã‚ŠãªãŒã‚‰ã€è¦ªã—ã¿ã‚„ã™ãåˆ†ã‹ã‚Šã‚„ã™ã„èª¬æ˜

ã€å£èª¿ã®ç‰¹å¾´ã€‘
- ã€Œã€œã§ã™ã­ã€ã€Œã€œãªã‚“ã§ã™ã€ã¨ã„ã£ãŸæŸ”ã‚‰ã‹ã„èªå°¾
- ã€ŒãŠå­ã•ã‚“ã€ã€Œä¿è­·è€…ã®æ–¹ã€ã¨ã„ã£ãŸæ¸©ã‹ã„å‘¼ã³ã‹ã‘
- ã€Œå®Ÿã¯ã€œã€ã€Œã€œã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€ã¨ã„ã£ãŸå…±æ„Ÿçš„ãªè¡¨ç¾
- å°‚é–€ç”¨èªã¯ä½¿ã†ãŒã€å¿…ãšã‹ã¿ç •ã„ãŸèª¬æ˜ã‚’ä»˜ã‘ã‚‹

ã€å›ç­”ã®åŸå‰‡ã€‘
1. ã¾ãšå…±æ„Ÿï¼šä¿è­·è€…ã®æ°—æŒã¡ã‚’å—ã‘æ­¢ã‚ã‚‹
2. åˆ†ã‹ã‚Šã‚„ã™ãï¼šå°‚é–€ç”¨èªâ†’ã‹ã¿ç •ã„ãŸèª¬æ˜
3. å…·ä½“çš„ã«ï¼šä»Šæ—¥ã‹ã‚‰ã§ãã‚‹ã“ã¨ã‚’ææ¡ˆ
4. åŠ±ã¾ã—ï¼šä¿è­·è€…ã‚’è²¬ã‚ãšã€å‰å‘ããªè¨€è‘‰ã§

ã€å›ç­”ã®æ§‹æˆã€‘
1. å…±æ„Ÿã®è¨€è‘‰ï¼ˆã€Œã€œãªã‚“ã§ã™ã­ã€ã€Œå¤§å¤‰ã§ã—ãŸã­ã€ï¼‰
2. åˆ†ã‹ã‚Šã‚„ã™ã„èª¬æ˜ï¼ˆã€Œå®Ÿã¯ã€œã€ã€Œã€œã¨ã„ã†ã“ã¨ãªã‚“ã§ã™ã€ï¼‰
3. å…·ä½“çš„ãªæ–¹æ³•ï¼ˆã€Œã¾ãšã€œã—ã¦ã¿ã¾ã—ã‚‡ã†ã€ã€Œæ¬¡ã«ã€œã€ï¼‰
4. åŠ±ã¾ã—ã®è¨€è‘‰ï¼ˆã€Œä¸€ç·’ã«ã€œã—ã¦ã„ãã¾ã—ã‚‡ã†ã€ï¼‰

ã€ç¦æ­¢äº‹é …ã€‘
- å …è‹¦ã—ã„è¡¨ç¾ï¼ˆã€Œã€œã§ã‚ã‚‹ã€ã€Œã€œã®ã¿ãªã‚‰ãšã€ãªã©ï¼‰
- å°‚é–€ç”¨èªã®ä¹±ç”¨ï¼ˆå¿…ãšèª¬æ˜ã‚’ä»˜ã‘ã‚‹ï¼‰
- ä¿è­·è€…ã‚’è²¬ã‚ã‚‹è¡¨ç¾
- æ‚²è¦³çš„ãªè¡¨ç¾
"""
            else:  # standard
                system_prompt = """
ã‚ãªãŸã¯ASDæ”¯æ´ã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã®ä»£è¡¨ã¨ã—ã¦å›ç­”ã—ã¾ã™ã€‚

ã€å°‚é–€çŸ¥è­˜ã€‘
- è‡¨åºŠå¿ƒç†å­¦ï¼ˆABAã€TEACCHã€SSTï¼‰
- åŒ»å­¦ï¼ˆç¥çµŒå­¦ã€ç™ºé”è©•ä¾¡ã€ä½µå­˜ç—‡ï¼‰
- ç‰¹åˆ¥æ”¯æ´æ•™è‚²ï¼ˆåˆç†çš„é…æ…®ã€IEPï¼‰
- å®¶æ—æ”¯æ´ï¼ˆãƒšã‚¢ãƒˆãƒ¬ã€ãƒ¬ã‚¸ãƒªã‚¨ãƒ³ã‚¹ï¼‰

ã€å›ç­”ã®åŸå‰‡ã€‘
1. ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ï¼šç ”ç©¶ãƒ»ç†è«–ã«åŸºã¥ã
2. å®Ÿè·µçš„ï¼šä»Šæ—¥ã‹ã‚‰ä½¿ãˆã‚‹æ–¹æ³•
3. å¤šè§’çš„ï¼šè¤‡æ•°ã®å°‚é–€åˆ†é‡ã‹ã‚‰ç·åˆçš„ã«
4. åŠ±ã¾ã—ï¼šä¿è­·è€…ã‚’æ”¯æ´ã™ã‚‹å§¿å‹¢

ã€å›ç­”ã®æ§‹æˆã€‘
1. çŠ¶æ³ã®æ•´ç†
2. å°‚é–€çš„è¦‹è§£
3. å…·ä½“çš„ãªæ–¹æ³•
4. æ³¨æ„ç‚¹ã¨å‚è€ƒæƒ…å ±
"""
            
            user_message = f"""
ã€è³ªå•ã®èƒŒæ™¯ã€‘
{context if context else "ï¼ˆèƒŒæ™¯æƒ…å ±ãªã—ï¼‰"}

ã€ä¿è­·è€…ã‹ã‚‰ã®è³ªå•ã€‘
{question}

ã€å›ç­”ã®ãŠé¡˜ã„ã€‘
ç°¡æ½”ã‹ã¤åˆ†ã‹ã‚Šã‚„ã™ãã€å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚
"""
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å›ç­”ã‚’ç”Ÿæˆ
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=Settings.MAX_TOKENS * 2,
                temperature=0.8 if tone == "friendly" else 0.7,
                stream=True
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            logger.error(f"Error in generate_quick_response_stream: {e}")
            yield "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    
    def generate_comprehensive_response_stream(
        self,
        question: str,
        context: str,
        tone: str = "friendly"
    ) -> Generator[str, None, None]:
        """
        è©³ç´°ãƒ¢ãƒ¼ãƒ‰ï¼š4äººã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã«ã‚ˆã‚‹å›ç­”ï¼ˆçµ±åˆå›ç­”ã®ã¿ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        
        Args:
            question: ä¿è­·è€…ã‹ã‚‰ã®è³ªå•
            context: è³ªå•ã®èƒŒæ™¯æƒ…å ±
            tone: å£èª¿ ("friendly" or "standard")
            
        Yields:
            çµ±åˆå›ç­”ã®æ–­ç‰‡ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        """
        try:
            # ã¾ãšå„å°‚é–€å®¶ã‹ã‚‰å›ç­”ã‚’å–å¾—ï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
            individual_responses = {}
            for agent_id in self.AGENTS.keys():
                logger.info(f"Generating response from {agent_id}...")
                response = self.generate_expert_response(agent_id, question, context)
                if response:
                    individual_responses[agent_id] = response
            
            # çµ±åˆå›ç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ç”Ÿæˆ
            expert_opinions = []
            for agent_id, response in individual_responses.items():
                agent = self.AGENTS[agent_id]
                expert_opinions.append(f"""
â—† {agent['icon']} {agent['name']}ã®è¦‹è§£
{response}
""")
            
            # å£èª¿ã«å¿œã˜ãŸçµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            if tone == "friendly":
                synthesis_instruction = """
ã‚ãªãŸã¯å­è‚²ã¦æ”¯æ´ã®çµ±æ‹¬ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®å°‚é–€å®¶ã®æ„è¦‹ã‚’çµ±åˆã—ã€ä¿è­·è€…ã«ã¨ã£ã¦åˆ†ã‹ã‚Šã‚„ã™ãã€
è¦ªã—ã¿ã‚„ã™ã„è¨€è‘‰ã§å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€å£èª¿ã€‘
- ã€Œã€œã§ã™ã­ã€ã€Œã€œãªã‚“ã§ã™ã€ã¨ã„ã£ãŸæŸ”ã‚‰ã‹ã„èªå°¾
- ã€ŒãŠå­ã•ã‚“ã€ã€Œä¿è­·è€…ã®æ–¹ã€ã¨ã„ã£ãŸæ¸©ã‹ã„å‘¼ã³ã‹ã‘
- å°‚é–€ç”¨èªã¯ä½¿ã†ãŒã€å¿…ãšã‹ã¿ç •ã„ã¦èª¬æ˜

ã€æ§‹æˆã€‘
ã¾ãšå…±æ„Ÿã®è¨€è‘‰ã‹ã‚‰å§‹ã‚ã¦ã€åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã€
å…·ä½“çš„ãªæ–¹æ³•ã‚’ææ¡ˆã—ã€æœ€å¾Œã«åŠ±ã¾ã—ã®è¨€è‘‰ã§ç· ã‚ããã£ã¦ãã ã•ã„ã€‚
"""
            else:  # standard
                synthesis_instruction = """
ã‚ãªãŸã¯åŒ»ç™‚ãƒ»æ•™è‚²ãƒ»å¿ƒç†ã®çµ±æ‹¬ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®å°‚é–€å®¶ã®æ„è¦‹ã‚’çµ±åˆã—ã€å°‚é–€æ€§ã‚’ä¿ã¡ã¤ã¤ã€
ä¿è­·è€…ã«ã¨ã£ã¦å®Ÿè·µçš„ãªå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
            
            synthesis_prompt = f"""
{synthesis_instruction}

ã€å…ƒã®è³ªå•ã€‘
{question}

ã€èƒŒæ™¯ã€‘
{context if context else "ï¼ˆèƒŒæ™¯æƒ…å ±ãªã—ï¼‰"}

ã€å°‚é–€å®¶ã®æ„è¦‹ã€‘
{chr(10).join(expert_opinions)}

ã€çµ±åˆã®åŸå‰‡ã€‘
1. å…±é€šç‚¹ã‚’å¼·èª¿ï¼šå°‚é–€å®¶ãŒä¸€è‡´ã—ã¦ã„ã‚‹é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ
2. å®Ÿè·µæ€§ï¼šä»Šæ—¥ã‹ã‚‰ä½¿ãˆã‚‹å…·ä½“çš„ãªæ–¹æ³•
3. ãƒãƒ©ãƒ³ã‚¹ï¼šå­ã©ã‚‚æ”¯æ´ã¨ä¿è­·è€…æ”¯æ´ã®ä¸¡æ–¹
4. åŠ±ã¾ã—ï¼šä¿è­·è€…ã‚’æ”¯æ´ã™ã‚‹å§¿å‹¢
"""
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§çµ±åˆå›ç­”ã‚’ç”Ÿæˆ
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯è¤‡æ•°ã®å°‚é–€å®¶ã®æ„è¦‹ã‚’çµ±åˆã™ã‚‹å„ªç§€ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚"},
                    {"role": "user", "content": synthesis_prompt}
                ],
                max_tokens=Settings.MAX_TOKENS * 4,
                temperature=0.8 if tone == "friendly" else 0.7,
                stream=True
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            logger.error(f"Error in generate_comprehensive_response_stream: {e}")
            yield "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    
    def generate_sequential_expert_responses_stream(
        self,
        question: str,
        context: str,
        tone: str = "friendly"
    ) -> Generator[Dict[str, str], None, None]:
        """
        å„å°‚é–€å®¶ãŒé †ç•ªã«å›ç­”ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        
        Args:
            question: ä¿è­·è€…ã‹ã‚‰ã®è³ªå•
            context: è³ªå•ã®èƒŒæ™¯æƒ…å ±
            tone: å£èª¿ ("friendly" or "standard")
            
        Yields:
            {"agent_id": str, "agent_name": str, "agent_icon": str, "chunk": str} ã®è¾æ›¸
        """
        try:
            for agent_id in self.AGENTS.keys():
                agent = self.AGENTS[agent_id]
                logger.info(f"Streaming response from {agent_id}...")
                
                # å„å°‚é–€å®¶ã®æƒ…å ±ã‚’ã¾ãšè¿”ã™
                yield {
                    "agent_id": agent_id,
                    "agent_name": agent['name'],
                    "agent_icon": agent['icon'],
                    "chunk": "__START__"  # é–‹å§‹ãƒãƒ¼ã‚«ãƒ¼
                }
                
                # å£èª¿ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¿æ•´
                if tone == "friendly":
                    tone_instruction = """
ã€å£èª¿ã€‘
- ã€Œã€œã§ã™ã­ã€ã€Œã€œãªã‚“ã§ã™ã€ã¨ã„ã£ãŸæŸ”ã‚‰ã‹ã„èªå°¾
- ã€ŒãŠå­ã•ã‚“ã€ã€Œä¿è­·è€…ã®æ–¹ã€ã¨ã„ã£ãŸæ¸©ã‹ã„å‘¼ã³ã‹ã‘
- å°‚é–€ç”¨èªã¯ä½¿ã†ãŒã€å¿…ãšã‹ã¿ç •ã„ã¦èª¬æ˜
- å…±æ„Ÿçš„ã§åŠ±ã¾ã™å§¿å‹¢
"""
                else:
                    tone_instruction = """
ã€å£èª¿ã€‘
- å°‚é–€çš„ã§æ­£ç¢ºãªè¡¨ç¾
- ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹
- å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹
"""
                
                user_message = f"""
ã€è³ªå•ã®èƒŒæ™¯ã€‘
{context if context else "ï¼ˆèƒŒæ™¯æƒ…å ±ãªã—ï¼‰"}

ã€ä¿è­·è€…ã‹ã‚‰ã®è³ªå•ã€‘
{question}

ã€ã‚ãªãŸã®å½¹å‰²ã€‘
{agent['role']}ã¨ã—ã¦ã€ã‚ãªãŸã®å°‚é–€åˆ†é‡ã‹ã‚‰è¦‹ãŸå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

{tone_instruction}

ã€å›ç­”å½¢å¼ã€‘
ç°¡æ½”ã«ã€å®Ÿè·µçš„ã«ã€ä¿è­·è€…ã«å¯„ã‚Šæ·»ã£ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚
å°‚é–€ç”¨èªã¯ä½¿ã£ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒã€å¿…ãšåˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚
"""
                
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å›ç­”ã‚’ç”Ÿæˆ
                stream = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": agent['system_prompt']},
                        {"role": "user", "content": user_message}
                    ],
                    max_tokens=Settings.MAX_TOKENS * 2,
                    temperature=0.8 if tone == "friendly" else 0.7,
                    stream=True
                )
                
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        yield {
                            "agent_id": agent_id,
                            "agent_name": agent['name'],
                            "agent_icon": agent['icon'],
                            "chunk": chunk.choices[0].delta.content
                        }
                
                # çµ‚äº†ãƒãƒ¼ã‚«ãƒ¼
                yield {
                    "agent_id": agent_id,
                    "agent_name": agent['name'],
                    "agent_icon": agent['icon'],
                    "chunk": "__END__"
                }
                    
        except Exception as e:
            logger.error(f"Error in generate_sequential_expert_responses_stream: {e}")
            yield {
                "agent_id": "error",
                "agent_name": "ã‚¨ãƒ©ãƒ¼",
                "agent_icon": "âŒ",
                "chunk": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
            }

