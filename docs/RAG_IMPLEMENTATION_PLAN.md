# RAG å®Ÿè£…ãƒ—ãƒ©ãƒ³

## ğŸ“Š æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ¯”è¼ƒ

### Option 1: LangChainï¼ˆæ¨å¥¨ï¼‰

**ãƒ¡ãƒªãƒƒãƒˆï¼š**

- âœ… æœ€ã‚‚æˆç†Ÿã—ãŸã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ 
- âœ… OpenAI ã¨ã®çµ±åˆãŒç°¡å˜
- âœ… è±Šå¯Œãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨äº‹ä¾‹
- âœ… ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®é¸æŠè‚¢ãŒå¤šã„
- âœ… æ—¥æœ¬èªã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒæ´»ç™º

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆï¼š**

- âš ï¸ ä¾å­˜é–¢ä¿‚ãŒå¤šã„
- âš ï¸ å­¦ç¿’æ›²ç·šãŒã‚„ã‚„æ€¥

**æ¨å¥¨ãƒ™ã‚¯ãƒˆãƒ« DBï¼š**

- **Chroma**: è»½é‡ã€ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºã«æœ€é©
- **Pinecone**: æœ¬ç•ªç’°å¢ƒå‘ã‘ã€ãƒãƒãƒ¼ã‚¸ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹
- **FAISS**: é«˜é€Ÿã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„

### Option 2: LlamaIndex

**ãƒ¡ãƒªãƒƒãƒˆï¼š**

- âœ… ãƒ‡ãƒ¼ã‚¿æ¥ç¶šã«ç‰¹åŒ–
- âœ… ã‚·ãƒ³ãƒ—ãƒ«ãª API
- âœ… RAG ã«æœ€é©åŒ–ã•ã‚ŒãŸè¨­è¨ˆ

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆï¼š**

- âš ï¸ LangChain ã‚ˆã‚Šã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ãŒå°ã•ã„

### Option 3: ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£…

**ãƒ¡ãƒªãƒƒãƒˆï¼š**

- âœ… å®Œå…¨ãªã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
- âœ… è»½é‡ãªä¾å­˜é–¢ä¿‚

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆï¼š**

- âŒ é–‹ç™ºæ™‚é–“ãŒé•·ã„
- âŒ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚³ã‚¹ãƒˆãŒé«˜ã„

## ğŸ¯ æ¨å¥¨ï¼šLangChain + Chroma

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¯ **LangChain + Chroma** ã®çµ„ã¿åˆã‚ã›ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

### ç†ç”±

1. **é–‹ç™ºåŠ¹ç‡**: ã™ãã«ä½¿ã„å§‹ã‚ã‚‰ã‚Œã‚‹
2. **ã‚³ã‚¹ãƒˆ**: Chroma ã¯ç„¡æ–™ã§ä½¿ãˆã‚‹
3. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: å°†æ¥çš„ã« Pinecone ãªã©ã«ç§»è¡Œå¯èƒ½
4. **æ—¥æœ¬èªå¯¾å¿œ**: æ—¥æœ¬èªã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œ

## ğŸš€ å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—

### Phase 1: åŸºæœ¬ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆ1-2 æ—¥ï¼‰

```bash
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install langchain chromadb tiktoken
```

**å®Ÿè£…å†…å®¹ï¼š**

- RAGService ã®åŸºæœ¬å®Ÿè£…
- Chroma ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
- OpenAI Embeddings ã®çµ±åˆ

### Phase 2: çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ï¼ˆ3-5 æ—¥ï¼‰

**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼š**

1. ASD æ”¯æ´ã«é–¢ã™ã‚‹å…¬é–‹æ–‡çŒ®
2. åšç”ŸåŠ´åƒçœã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
3. ç™‚è‚²æ©Ÿé–¢ã®å…¬é–‹æƒ…å ±
4. å°‚é–€æ›¸ç±ã®è¦ç´„

**ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼š**

```python
# ä¾‹ï¼šãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰
documents = [
    {
        "content": "ASDã®æ„Ÿè¦šéæ•ã«ã¤ã„ã¦...",
        "metadata": {
            "event": "åºŠå±‹",
            "category": "æ„Ÿè¦šéæ•",
            "source": "åšç”ŸåŠ´åƒçœã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³"
        }
    },
    # ...
]
```

### Phase 3: æ¤œç´¢ãƒ»çµ±åˆï¼ˆ2-3 æ—¥ï¼‰

**å®Ÿè£…å†…å®¹ï¼š**

- ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã®å®Ÿè£…
- AI ç”Ÿæˆã¨ã®çµ±åˆ
- æ¤œç´¢ç²¾åº¦ã®è©•ä¾¡

### Phase 4: æœ€é©åŒ–ï¼ˆç¶™ç¶šçš„ï¼‰

- ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®å®Ÿè£…
- ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

## ğŸ’» å®Ÿè£…ä¾‹

### 1. requirements.txt ã®æ›´æ–°

```txt
# æ—¢å­˜ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
streamlit>=1.28.0
openai>=1.0.0
python-dotenv>=1.0.0
pandas>=2.0.0
plotly>=5.17.0
pytest>=7.4.0

# RAGé–¢é€£ã®è¿½åŠ 
langchain>=0.1.0
chromadb>=0.4.0
tiktoken>=0.5.0
```

### 2. RAGService ã®å®Ÿè£…

```python
# app/services/rag_service.py
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from typing import List, Dict, Optional
import logging

logger = logging.getLogger(__name__)


class RAGService:
    """RAGã‚µãƒ¼ãƒ“ã‚¹ - LangChain + Chromaå®Ÿè£…"""

    def __init__(self, persist_directory: str = "./data/chroma_db"):
        """
        RAGServiceã®åˆæœŸåŒ–

        Args:
            persist_directory: Chromaãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¿å­˜å…ˆ
        """
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-ada-002"
        )

        # Chromaãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®åˆæœŸåŒ–
        self.vectorstore = Chroma(
            persist_directory=persist_directory,
            embedding_function=self.embeddings,
            collection_name="asd_knowledge"
        )

        logger.info("RAGService initialized with LangChain + Chroma")

    def add_documents(self, documents: List[Dict[str, str]]) -> bool:
        """
        çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«æ–‡æ›¸ã‚’è¿½åŠ 

        Args:
            documents: è¿½åŠ ã™ã‚‹æ–‡æ›¸ã®ãƒªã‚¹ãƒˆ
                [{"content": str, "metadata": dict}, ...]

        Returns:
            æˆåŠŸã—ãŸå ´åˆTrue
        """
        try:
            # Documentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
            docs = [
                Document(
                    page_content=doc["content"],
                    metadata=doc.get("metadata", {})
                )
                for doc in documents
            ]

            # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ï¼ˆé•·æ–‡ã®å ´åˆï¼‰
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50,
                separators=["\n\n", "\n", "ã€‚", "ã€", " "]
            )
            split_docs = text_splitter.split_documents(docs)

            # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«è¿½åŠ 
            self.vectorstore.add_documents(split_docs)
            self.vectorstore.persist()

            logger.info(f"Added {len(split_docs)} documents to RAG")
            return True

        except Exception as e:
            logger.error(f"Error adding documents: {e}")
            return False

    def retrieve_relevant_context(
        self,
        query: str,
        event: str = None,
        top_k: int = 3
    ) -> Optional[str]:
        """
        é–¢é€£ã™ã‚‹å°‚é–€çŸ¥è­˜ã‚’å–å¾—

        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            event: ã‚¤ãƒ™ãƒ³ãƒˆåã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            top_k: å–å¾—ã™ã‚‹æ–‡æ›¸æ•°

        Returns:
            é–¢é€£ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—åˆ—
        """
        try:
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®æ§‹ç¯‰
            filter_dict = {}
            if event:
                filter_dict["event"] = event

            # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
            results = self.vectorstore.similarity_search(
                query=query,
                k=top_k,
                filter=filter_dict if filter_dict else None
            )

            if not results:
                logger.warning(f"No relevant documents found for query: {query}")
                return None

            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰
            context_parts = []
            for i, doc in enumerate(results, 1):
                source = doc.metadata.get("source", "ä¸æ˜")
                content = doc.page_content
                context_parts.append(
                    f"ã€å‚è€ƒæƒ…å ± {i}ã€‘ï¼ˆå‡ºå…¸: {source}ï¼‰\n{content}"
                )

            context = "\n\n".join(context_parts)
            logger.info(f"Retrieved {len(results)} relevant documents")

            return context

        except Exception as e:
            logger.error(f"Error retrieving context: {e}")
            return None

    def search_with_score(
        self,
        query: str,
        k: int = 5,
        score_threshold: float = 0.7
    ) -> List[Dict]:
        """
        ã‚¹ã‚³ã‚¢ä»˜ãã§æ¤œç´¢

        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            k: å–å¾—ã™ã‚‹çµæœæ•°
            score_threshold: æœ€å°ã‚¹ã‚³ã‚¢é–¾å€¤

        Returns:
            æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ
        """
        try:
            results = self.vectorstore.similarity_search_with_score(
                query=query,
                k=k
            )

            # ã‚¹ã‚³ã‚¢ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered_results = [
                {
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "score": score
                }
                for doc, score in results
                if score >= score_threshold
            ]

            return filtered_results

        except Exception as e:
            logger.error(f"Error in search_with_score: {e}")
            return []
```

### 3. çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
# scripts/initialize_rag.py
"""
RAGçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sys
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.services.rag_service import RAGService

def load_initial_knowledge():
    """åˆæœŸçŸ¥è­˜ã‚’èª­ã¿è¾¼ã‚€"""

    # ASDæ”¯æ´ã«é–¢ã™ã‚‹åŸºç¤çŸ¥è­˜
    knowledge_base = [
        {
            "content": """
ASDã®æ„Ÿè¦šéæ•ã«ã¤ã„ã¦ï¼š
ASDï¼ˆè‡ªé–‰ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ç—‡ï¼‰ã®ãŠå­ã•ã‚“ã¯ã€è´è¦šã€è§¦è¦šã€è¦–è¦šãªã©ã®æ„Ÿè¦šãŒ
é€šå¸¸ã‚ˆã‚Šã‚‚æ•æ„Ÿã§ã‚ã‚‹ã“ã¨ãŒå¤šãã€æ—¥å¸¸çš„ãªéŸ³ã‚„åˆºæ¿€ãŒè‹¦ç—›ã«æ„Ÿã˜ã‚‰ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ç‰¹ã«äºˆæ¸¬ã§ããªã„å¤§ããªéŸ³ï¼ˆãƒãƒªã‚«ãƒ³ã€ãƒ‰ãƒ©ã‚¤ãƒ¤ãƒ¼ãªã©ï¼‰ã¯å¼·ã„ä¸å®‰ã‚„ãƒ‘ãƒ‹ãƒƒã‚¯ã‚’
å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
            """.strip(),
            "metadata": {
                "event": "åºŠå±‹",
                "category": "æ„Ÿè¦šéæ•",
                "source": "ASDæ”¯æ´ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³"
            }
        },
        {
            "content": """
äº‹å‰äºˆå‘Šã®é‡è¦æ€§ï¼š
ASDã®ãŠå­ã•ã‚“ã¯ã€äºˆæ¸¬å¯èƒ½æ€§ãŒã‚ã‚‹ã¨å®‰å¿ƒã—ã¾ã™ã€‚ã“ã‚Œã‹ã‚‰ä½•ãŒèµ·ã“ã‚‹ã‹ã‚’
äº‹å‰ã«ä¼ãˆã‚‹ã“ã¨ã§ã€ä¸å®‰ã‚’å¤§å¹…ã«è»½æ¸›ã§ãã¾ã™ã€‚è¦–è¦šçš„ãªæ‰‹é †æ›¸ã‚„
ã‚¿ã‚¤ãƒ ã‚¿ã‚¤ãƒãƒ¼ãªã©ã®è¦–è¦šæ”¯æ´ã‚’ä½µç”¨ã™ã‚‹ã¨ã€ã•ã‚‰ã«åŠ¹æœçš„ã§ã™ã€‚
            """.strip(),
            "metadata": {
                "event": "åºŠå±‹",
                "category": "äº‹å‰äºˆå‘Š",
                "source": "ç™‚è‚²å®Ÿè·µã‚¬ã‚¤ãƒ‰"
            }
        },
        {
            "content": """
è¦–è¦šæ”¯æ´ã®åŠ¹æœï¼š
ASDã®ãŠå­ã•ã‚“ã®å¤šãã¯è¦–è¦šæƒ…å ±ã®å‡¦ç†ãŒå¾—æ„ã§ã™ã€‚æ‰‹é †ã‚’çµµã‚«ãƒ¼ãƒ‰ã‚„ã‚¤ãƒ©ã‚¹ãƒˆã§
ç¤ºã™ã“ã¨ã§ã€ç†è§£ãŒæ·±ã¾ã‚Šã€è¦‹é€šã—ãŒæŒã¦ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Š
ä¸å®‰ãŒè»½æ¸›ã•ã‚Œã€é©åˆ‡ãªè¡Œå‹•ã‚’ã¨ã‚Šã‚„ã™ããªã‚Šã¾ã™ã€‚
            """.strip(),
            "metadata": {
                "event": "åºŠå±‹",
                "category": "è¦–è¦šæ”¯æ´",
                "source": "TEACCH ãƒ—ãƒ­ã‚°ãƒ©ãƒ "
            }
        },
        {
            "content": """
ã”è¤’ç¾ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã‚¨ã‚³ãƒãƒŸãƒ¼ï¼‰ï¼š
é©åˆ‡ãªè¡Œå‹•ã«å¯¾ã—ã¦å³åº§ã«ã”è¤’ç¾ã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã€ãã®è¡Œå‹•ãŒå¼·åŒ–ã•ã‚Œã¾ã™ã€‚
ã‚·ãƒ¼ãƒ«ã‚„ã‚¹ã‚¿ãƒ³ãƒ—ãªã©è¦–è¦šçš„ã«åˆ†ã‹ã‚Šã‚„ã™ã„ã”è¤’ç¾ã¯ã€ASDã®ãŠå­ã•ã‚“ã«
ç‰¹ã«åŠ¹æœçš„ã§ã™ã€‚å°ã•ãªæˆåŠŸä½“é¨“ã‚’ç©ã¿é‡ã­ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚
            """.strip(),
            "metadata": {
                "event": "åºŠå±‹",
                "category": "è¡Œå‹•å¼·åŒ–",
                "source": "å¿œç”¨è¡Œå‹•åˆ†æï¼ˆABAï¼‰"
            }
        },
        {
            "content": """
ç’°å¢ƒèª¿æ•´ã®é‡è¦æ€§ï¼š
ç„¡ç†ã«æ…£ã‚Œã•ã›ã‚‹ã‚ˆã‚Šã‚‚ã€ã¾ãšç’°å¢ƒã‚’èª¿æ•´ã™ã‚‹ã“ã¨ãŒå„ªå…ˆã§ã™ã€‚
ã‚¤ãƒ¤ãƒ¼ãƒãƒ•ã§ã®éŸ³ã®è»½æ¸›ã€ã‚¿ã‚ªãƒ«ãƒ‰ãƒ©ã‚¤ã§ã®ãƒ‰ãƒ©ã‚¤ãƒ¤ãƒ¼å›é¿ãªã©ã€
å­ã©ã‚‚ã®æ„Ÿè¦šç‰¹æ€§ã«åˆã‚ã›ãŸé…æ…®ãŒã€é•·æœŸçš„ãªé©å¿œã«ã¤ãªãŒã‚Šã¾ã™ã€‚
            """.strip(),
            "metadata": {
                "event": "åºŠå±‹",
                "category": "ç’°å¢ƒèª¿æ•´",
                "source": "æ„Ÿè¦šçµ±åˆç™‚æ³•"
            }
        }
    ]

    return knowledge_base


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ RAGçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã™...")

    # RAGã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
    rag_service = RAGService()

    # åˆæœŸçŸ¥è­˜ã®èª­ã¿è¾¼ã¿
    knowledge = load_initial_knowledge()
    print(f"ğŸ“š {len(knowledge)}ä»¶ã®çŸ¥è­˜ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
    success = rag_service.add_documents(knowledge)

    if success:
        print("âœ… RAGçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

        # ãƒ†ã‚¹ãƒˆæ¤œç´¢
        print("\nğŸ” ãƒ†ã‚¹ãƒˆæ¤œç´¢ã‚’å®Ÿè¡Œ...")
        context = rag_service.retrieve_relevant_context(
            query="ãƒãƒªã‚«ãƒ³ã®éŸ³ã§å­ã©ã‚‚ãŒãƒ‘ãƒ‹ãƒƒã‚¯ã«ãªã‚‹",
            event="åºŠå±‹",
            top_k=2
        )

        if context:
            print("\n--- æ¤œç´¢çµæœ ---")
            print(context)
        else:
            print("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    else:
        print("âŒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()
```

### 4. AI ç”Ÿæˆã¸ã®çµ±åˆ

```python
# app/pages/parent_guide.pyã®ä¿®æ­£ä¾‹

# RAGã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from app.services.rag_service import RAGService

def display_ai_feedback(
    action_text: str,
    evaluation: str,
    event: str,
    child_action: str,
    action_idx: int
):
    """AIã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡¨ç¤ºï¼ˆRAGçµ±åˆç‰ˆï¼‰"""

    # ... æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ ...

    # RAGã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
    try:
        rag_service = RAGService()

        # é–¢é€£ã™ã‚‹å°‚é–€çŸ¥è­˜ã‚’å–å¾—
        rag_context = rag_service.retrieve_relevant_context(
            query=f"{event}ã§{child_action}ã¸ã®å¯¾å¿œ",
            event=event,
            top_k=2
        )
    except Exception as e:
        logger.warning(f"RAG retrieval failed: {e}")
        rag_context = None

    # è©³ç´°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®è¡¨ç¤ºï¼ˆRAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãï¼‰
    if show_detailed:
        detailed_feedback_key = f"detailed_feedback_{event}_{child_action}_{action_text}_{ai_mode}"

        if detailed_feedback_key not in st.session_state:
            with st.spinner("AIãŒè©³ç´°ãªè§£èª¬ã‚’ç”Ÿæˆä¸­ï¼ˆå°‚é–€çŸ¥è­˜ã‚’å‚ç…§ä¸­ï¼‰..."):
                ai_service = AIService()

                detailed_placeholder = st.empty()
                detailed_content = ""

                try:
                    for chunk in ai_service.generate_parent_action_feedback_stream(
                        event=event,
                        child_action=child_action,
                        parent_action=action_text,
                        evaluation=evaluation,
                        ai_mode=ai_mode,
                        detail_level="detailed",
                        rag_context=rag_context  # RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¸¡ã™
                    ):
                        detailed_content += chunk
                        detailed_placeholder.markdown(
                            f"""
                            <div style="padding: 1.5rem; background-color: #F3E5F5;
                            border-radius: 0.5rem; border-left: 4px solid #9C27B0; margin-top: 1rem;">
                                <h4 style="margin-top: 0; color: #6A1B9A;">ğŸ“š è©³ç´°ãªè§£èª¬</h4>
                                <div style="white-space: pre-wrap; margin-bottom: 0;">{detailed_content}</div>
                            </div>
                            """,
                            unsafe_allow_html=True
                        )

                    st.session_state[detailed_feedback_key] = detailed_content

                except Exception as e:
                    ErrorHandler.handle_error(e, "è©³ç´°ãªè§£èª¬ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                    st.error("ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚è©³ç´°ãªè§£èª¬ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
```

## ğŸ“¦ å¿…è¦ãªè¿½åŠ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸

```txt
# RAGå®Ÿè£…ã«å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
langchain>=0.1.0          # RAGãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
chromadb>=0.4.0           # ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
tiktoken>=0.5.0           # ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
```

## ğŸ¯ å®Ÿè£…ã®å„ªå…ˆé †ä½

### Phase 1ï¼ˆä»Šã™ãå¯èƒ½ï¼‰

- âœ… requirements.txt ã®æ›´æ–°
- âœ… RAGService ã®å®Ÿè£…ï¼ˆLangChain ç‰ˆï¼‰
- âœ… åˆæœŸçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰

### Phase 2ï¼ˆ1-2 é€±é–“å¾Œï¼‰

- â³ ã‚ˆã‚Šå¤šãã®å°‚é–€çŸ¥è­˜ã®è¿½åŠ 
- â³ æ¤œç´¢ç²¾åº¦ã®è©•ä¾¡ã¨æ”¹å–„
- â³ ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®å®Ÿè£…

### Phase 3ï¼ˆ1 ãƒ¶æœˆå¾Œï¼‰

- â³ æœ¬ç•ªç’°å¢ƒã¸ã®å±•é–‹
- â³ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- â³ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®åé›†

## ğŸ’° ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š

### OpenAI Embeddings API

- **ãƒ¢ãƒ‡ãƒ«**: text-embedding-ada-002
- **ã‚³ã‚¹ãƒˆ**: $0.0001 / 1K tokens
- **åˆæœŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹**: ç´„ 10,000 ãƒˆãƒ¼ã‚¯ãƒ³ = $0.001
- **æ¤œç´¢ã‚¯ã‚¨ãƒª**: ç´„ 100 ãƒˆãƒ¼ã‚¯ãƒ³/å› = $0.00001/å›

### Chromaï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰

- **ã‚³ã‚¹ãƒˆ**: ç„¡æ–™
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ã‚¹ã‚¯

### æœˆé–“ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Šï¼ˆ1000 ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰

- æ¤œç´¢: 1000 å› Ã— $0.00001 = $0.01
- æ–°è¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: æœˆ 1 å›æ›´æ–° = $0.001
- **åˆè¨ˆ**: ç´„ $0.01/æœˆï¼ˆç„¡è¦–ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ï¼‰

## ğŸ”„ ä»£æ›¿æ¡ˆï¼šPineconeï¼ˆæœ¬ç•ªç’°å¢ƒå‘ã‘ï¼‰

å°†æ¥çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹å ´åˆï¼š

```python
from langchain.vectorstores import Pinecone
import pinecone

# Pineconeã®åˆæœŸåŒ–
pinecone.init(
    api_key="YOUR_API_KEY",
    environment="us-east-1-aws"
)

vectorstore = Pinecone.from_existing_index(
    index_name="asd-knowledge",
    embedding=embeddings
)
```

**Pinecone ã®ãƒ¡ãƒªãƒƒãƒˆï¼š**

- ãƒãƒãƒ¼ã‚¸ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆé‹ç”¨ä¸è¦ï¼‰
- é«˜é€Ÿãƒ»é«˜å¯ç”¨æ€§
- è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

**ã‚³ã‚¹ãƒˆï¼š**

- ç„¡æ–™æ : 1 ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€100 ä¸‡ãƒ™ã‚¯ãƒˆãƒ«
- æœ‰æ–™: $70/æœˆã€œ

## ğŸ“š å‚è€ƒãƒªã‚½ãƒ¼ã‚¹

- [LangChain å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://python.langchain.com/)
- [Chroma å…¬å¼ã‚µã‚¤ãƒˆ](https://www.trychroma.com/)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)
- [RAG ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](https://www.pinecone.io/learn/retrieval-augmented-generation/)

## âœ… ã¾ã¨ã‚

**æ¨å¥¨å®Ÿè£…ï¼šLangChain + Chroma**

- ã™ãã«ä½¿ã„å§‹ã‚ã‚‰ã‚Œã‚‹
- ã‚³ã‚¹ãƒˆãŒä½ã„ï¼ˆã»ã¼ç„¡æ–™ï¼‰
- å°†æ¥çš„ãªæ‹¡å¼µæ€§ãŒã‚ã‚‹
- æ—¥æœ¬èªã«å¯¾å¿œ

å®Ÿè£…ã‚’é–‹å§‹ã™ã‚‹å ´åˆã¯ã€ã¾ãš`requirements.txt`ã‚’æ›´æ–°ã—ã¦ã€åŸºæœ¬çš„ãª RAGService ã‚’å®Ÿè£…ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚
